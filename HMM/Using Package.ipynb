{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fbbe40f-b91c-4992-949f-e9c42b9361c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from piohmm import HMM\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd5f642-0d50-4e10-89d9-a55e951c4d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x209fea935b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb913fd-9267-48af-9924-e83c4e7396f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 #number of samples\n",
    "d = 1 #dimensionality of observations\n",
    "t = 20 #number of time steps\n",
    "k = 2 #number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68447df-2894-42a2-952a-344b2b16ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[0.6, 0.4],[0.27, 0.73]]) #transition matrix\n",
    "a_dist = torch.distributions.dirichlet.Dirichlet(3 * torch.ones(k))\n",
    "pi = a_dist.sample() #inital state distributoin\n",
    "\n",
    "mu = torch.tensor([0., 2.]) # state means\n",
    "var = torch.tensor([0.1, 0.1]) #state covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae740c6b-57bc-45a1-9d81-d8018a7e3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2 #specify the range of a uniform distribution over personalized state effects, e.g. r_i ~ Unif[-b, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41af392e-a28f-411a-ab1b-afac895d3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros((n,t,d))\n",
    "Z = torch.zeros((n,t), dtype=torch.long)\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(t):\n",
    "        if j == 0:\n",
    "            Z[i, j] = torch.multinomial(pi, num_samples=1).byte()\n",
    "            # D[i, j] = torch.rand(1)\n",
    "            m_dist = torch.distributions.normal.Normal(\n",
    "                mu.index_select(0, Z[i, j]),\n",
    "                var.index_select(0, Z[i, j]))\n",
    "            X[i, j, :] = m_dist.sample()\n",
    "        else:\n",
    "            Z[i, j] = torch.multinomial(A[Z[i, j - 1], :], num_samples=1)\n",
    "            # D[i, j] = torch.rand(1)\n",
    "            m_dist = torch.distributions.normal.Normal(\n",
    "                mu.index_select(0, Z[i, j]),\n",
    "                var.index_select(0, Z[i, j]))\n",
    "            X[i, j, :] = m_dist.sample()\n",
    "\n",
    "X_hat = torch.zeros(n, t, d)\n",
    "\n",
    "l = 2.5 #lengthscale for the SE kernel\n",
    "s = 4 #sigma^2 for the SE kernel\n",
    "\n",
    "#build covariance matrix\n",
    "var_x = torch.zeros(t,t)\n",
    "t_vec = torch.range(0,t)\n",
    "for j in range(t):\n",
    "    for jj in range(t):\n",
    "        r = (t_vec[j] - t_vec[jj])**2\n",
    "        var_x[j, jj] = 1/s*torch.exp(-r/(2*l))\n",
    "\n",
    "L = torch.cholesky(var_x)\n",
    "b_stor = torch.zeros(n)\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    e = torch.randn(t)\n",
    "    b_stor[i] = 2*b*torch.rand(1) - b\n",
    "    X_hat[i, :, :] =  torch.einsum('ik,k->i', [L, e])[None, :, None] + X[i, :, :] + b_stor[i]*torch.ones(1,t,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b23472d-6a5a-4b11-92df-a81f35aca4fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "masked_select: expected BoolTensor for mask",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#fit a personalized hmm\u001b[39;00m\n\u001b[32m      2\u001b[39m piohmm = HMM(X_hat, k=k, full_cov=\u001b[38;5;28;01mFalse\u001b[39;00m, priorV=\u001b[38;5;28;01mFalse\u001b[39;00m, io=\u001b[38;5;28;01mFalse\u001b[39;00m, personalized=\u001b[38;5;28;01mTrue\u001b[39;00m, personalized_io=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      3\u001b[39m                    state_io=\u001b[38;5;28;01mFalse\u001b[39;00m, UT=\u001b[38;5;28;01mFalse\u001b[39;00m, device=\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m, eps=\u001b[32m1e-18\u001b[39m, priorMu=\u001b[38;5;28;01mTrue\u001b[39;00m, var_fill=\u001b[32m0.5\u001b[39m, lr=\u001b[32m0.005\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m piohmm_params, _, _, elbo, b_hat, _  = \u001b[43mpiohmm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermediate_save\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m piohmm_mps = piohmm.predict_sequence(piohmm_params, n_sample=b_hat)\n\u001b[32m      7\u001b[39m piohmm_xhat = np.zeros((n,t))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Akash\\Disease Progression Modelling\\HMM\\piohmm.py:935\u001b[39m, in \u001b[36mHMM.learn_model\u001b[39m\u001b[34m(self, num_iter, use_cc, cc, intermediate_save, load_model, model_name)\u001b[39m\n\u001b[32m    932\u001b[39m         prev_cost = obj\n\u001b[32m    934\u001b[39m     \u001b[38;5;66;03m#m-step, update the parameters\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m     params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mm_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43me_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.perso_io \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.perso:\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m params, e_out, \u001b[38;5;28mself\u001b[39m.ll, \u001b[38;5;28mself\u001b[39m.elbo, \u001b[38;5;28mself\u001b[39m.mu_hat, \u001b[38;5;28mself\u001b[39m.L_hat, \u001b[38;5;28mself\u001b[39m.nu_hat, \u001b[38;5;28mself\u001b[39m.N_hat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Akash\\Disease Progression Modelling\\HMM\\piohmm.py:855\u001b[39m, in \u001b[36mHMM.m_step\u001b[39m\u001b[34m(self, e_out, params, samples)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.k):\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.k):\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m         logA[i, j] = torch.logsumexp(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mom\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyte\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, dim=-\u001b[32m1\u001b[39m) - \\\n\u001b[32m    856\u001b[39m                           torch.logsumexp(torch.masked_select(xi[i, :, :, :], \u001b[38;5;28mself\u001b[39m.om[\u001b[38;5;28;01mNone\u001b[39;00m, :, \u001b[32m1\u001b[39m:].byte()), dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    857\u001b[39m A = logA.exp()\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ut:\n",
      "\u001b[31mRuntimeError\u001b[39m: masked_select: expected BoolTensor for mask"
     ]
    }
   ],
   "source": [
    "#fit a personalized hmm\n",
    "piohmm = HMM(X_hat, k=k, full_cov=False, priorV=False, io=False, personalized=True, personalized_io=False,\n",
    "                   state_io=False, UT=False, device='cpu', eps=1e-18, priorMu=True, var_fill=0.5, lr=0.005)\n",
    "piohmm_params, _, _, elbo, b_hat, _  = piohmm.learn_model(num_iter=1000, intermediate_save=False)\n",
    "piohmm_mps = piohmm.predict_sequence(piohmm_params, n_sample=b_hat)\n",
    "\n",
    "piohmm_xhat = np.zeros((n,t))\n",
    "piohmm_xvar = np.zeros((n,t))\n",
    "for i in range(n):\n",
    "    for j in range(t):\n",
    "        idx = np.where(piohmm_mps[i, j].numpy() == np.arange(k))[0][0]\n",
    "        piohmm_xhat[i,j] = piohmm_params['mu'][idx].numpy() + b_hat[i].detach().numpy()\n",
    "        piohmm_xvar[i,j] = 2*np.sqrt(piohmm_params['var'][idx].numpy())\n",
    "\n",
    "#fit a standard hmm\n",
    "hmm = HMM(X_hat, k=k, full_cov=False, priorV=False, io=False, personalized=False, personalized_io=False,\n",
    "             state_io=False, UT=False, device='cpu', eps=1e-18)\n",
    "hmm_params, _, ll = hmm.learn_model(num_iter=100, intermediate_save=False)\n",
    "hmm_mps = hmm.predict_sequence(hmm_params)\n",
    "\n",
    "hmm_xhat = np.zeros((n,t))\n",
    "hmm_xvar = np.zeros((n,t))\n",
    "for i in range(n):\n",
    "    for j in range(t):\n",
    "        idx = np.where(hmm_mps[i,j].numpy() == np.arange(k))[0][0]\n",
    "        hmm_xhat[i,j] = hmm_params['mu'][idx].numpy() \n",
    "        hmm_xvar[i,j] = 2*np.sqrt(hmm_params['var'][idx].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051dcb81-dc38-4464-91ff-a189596ce564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Disease Progression Modelling",
   "language": "python",
   "name": "dpm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
